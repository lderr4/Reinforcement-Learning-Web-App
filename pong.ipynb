{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# gym initialization\n",
    "env = gym.make('Pong-v0')\n",
    "observation = env.reset()\n",
    "prev_input = None\n",
    "# Declaring the two actions that can happen in Pong for an agent, move up or move down\n",
    "# Decalring 0 means staying still. Note that this is pre-defined specific to package.\n",
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "# Hyperparameters. Gamma here allows you to measure the effect of future events\n",
    "gamma = 0.99\n",
    "# initialization of variables used in the main loop\n",
    "x_train, y_train, rewards = [], [], []\n",
    "reward_sum = 0\n",
    "episode_num = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b43a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6000 (75x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop - remove 35px from start & 25px from end of image in x, to reduce redundant parts of image (i.e. after ball passes paddle)\n",
    "    I = I[::2,::2,0] # downsample by factor of 2.\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1. this makes the image grayscale effectively\n",
    "    return I.astype(np.float).ravel() # ravel flattens an array and collapses it into a column vector\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e595aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n",
      "(210, 160, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n",
      "(array([0., 1.]), array([6366,   34]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/bkzmld751m5fdgn8m3_kzfmc0000gn/T/ipykernel_3574/1888411344.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return I.astype(np.float).ravel() # ravel flattens an array and collapses it into a column vector\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(22):\n",
    "    if i > 20:\n",
    "        plt.imshow(observation)\n",
    "        plt.show() # before preprocessing\n",
    "    observation, _, _, _ = env.step(1)\n",
    "    print(observation.shape)\n",
    "    \n",
    "obs_preprocessed = prepro(observation).reshape(80,80)\n",
    "print(np.unique(obs_preprocessed,return_counts=True)) # binary array\n",
    "plt.imshow(obs_preprocessed, cmap='gray')\n",
    "plt.show() # after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c8ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(r, gamma): # idea: \n",
    "    r = np.array(r)\n",
    "    discounted_r = np.zeros(r.shape)\n",
    "    running_add = 0\n",
    "    print(discounted_r)\n",
    "\n",
    "    for t in reversed(range(0, len(r))): \n",
    "        \n",
    "        if r[t] != 0: running_add = 0 # if the game ended reset \n",
    "        running_add = running_add * gamma + r[t] \n",
    "        discounted_r[t] = running_add\n",
    "        \n",
    "    # not sure whether normalizing is helpful or not:\n",
    "    \n",
    "    # discounted_r -= np.mean(discounted_r) \n",
    "    # discounted_r /= np.std(discounted_r)\n",
    "    \n",
    "    \n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b58edfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 14:11:52.274289: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 200)               1280200   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,401\n",
      "Trainable params: 1,280,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# models\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "# optimizer \n",
    "from keras.optimizers import Adam # adaptive moment estimation, a type of stochastic gradient descent\n",
    "\n",
    "# callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200,\n",
    "                input_dim=80*80,\n",
    "                activation='relu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid',\n",
    "                kernel_initializer='RandomNormal'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "filepath = 'dumb_model.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "873bea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 7]\n",
      " [2 5 7]\n",
      " [3 6 7]\n",
      " [4 5 7]\n",
      " [5 4 7]]\n"
     ]
    }
   ],
   "source": [
    "a = [[1,2,3,4,5],[4,5,6,5,4], [7,7,7,7,7]]\n",
    "print(np.vstack(a).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dc7bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bh/bkzmld751m5fdgn8m3_kzfmc0000gn/T/ipykernel_3574/1888411344.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return I.astype(np.float).ravel() # ravel flattens an array and collapses it into a column vector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.38095238095238\n",
      "Episode Number:  0 | Total Reward:  -30.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.41294967 -0.41712088 -0.42133422 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "48.38095238095238\n",
      "Episode Number:  1 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42988901 -0.43423133 -0.4386175  ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "47.714285714285715\n",
      "Episode Number:  2 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.44304798 -0.44752321 -0.45204365 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "48.857142857142854\n",
      "Episode Number:  3 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42133422 -0.42559012 -0.42988901 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "48.80952380952381\n",
      "Episode Number:  4 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.43423133 -0.4386175  -0.44304798 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "48.714285714285715\n",
      "Episode Number:  5 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.41712088 -0.42133422 -0.42559012 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "49.142857142857146\n",
      "Episode Number:  6 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42133422 -0.42559012 -0.42988901 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "47.61904761904762\n",
      "Episode Number:  7 | Total Reward:  -21.0\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[-0.43423133 -0.4386175  -0.44304798 -0.44752321 -0.45204365 -0.45660975\n",
      " -0.46122197 -0.46588078 -0.47058664 -0.47534004 -0.48014146 -0.48499137\n",
      " -0.48989027 -0.49483866 -0.49983703 -0.50488589 -0.50998575 -0.51513712\n",
      " -0.52034052 -0.52559649 -0.53090554 -0.53626823 -0.54168508 -0.54715664\n",
      " -0.55268348 -0.55826614 -0.56390519 -0.5696012  -0.57535475 -0.58116641\n",
      " -0.58703678 -0.59296645 -0.59895601 -0.60500607 -0.61111724 -0.61729014\n",
      " -0.62352539 -0.62982363 -0.63618549 -0.6426116  -0.64910263 -0.65565922\n",
      " -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909 -0.69641322\n",
      " -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337 -0.73970037\n",
      " -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136 -0.78567814\n",
      " -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862 -0.83451376\n",
      " -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102 -0.88638487\n",
      " -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535 -0.94148015\n",
      " -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99       -1.\n",
      " -0.62982363 -0.63618549 -0.6426116  -0.64910263 -0.65565922 -0.66228204\n",
      " -0.66897176 -0.67572905 -0.6825546  -0.68944909 -0.69641322 -0.70344769\n",
      " -0.71055323 -0.71773053 -0.72498034 -0.73230337 -0.73970037 -0.74717209\n",
      " -0.75471929 -0.76234271 -0.77004315 -0.77782136 -0.78567814 -0.79361428\n",
      " -0.80163059 -0.80972787 -0.81790694 -0.82616862 -0.83451376 -0.84294319\n",
      " -0.85145777 -0.86005835 -0.86874581 -0.87752102 -0.88638487 -0.89533825\n",
      " -0.90438208 -0.91351725 -0.92274469 -0.93206535 -0.94148015 -0.95099005\n",
      " -0.96059601 -0.970299   -0.9801     -0.99       -1.         -0.6426116\n",
      " -0.64910263 -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546\n",
      " -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034\n",
      " -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315\n",
      " -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694\n",
      " -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581\n",
      " -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469\n",
      " -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801\n",
      " -0.99       -1.         -0.63618549 -0.6426116  -0.64910263 -0.65565922\n",
      " -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909 -0.69641322\n",
      " -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337 -0.73970037\n",
      " -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136 -0.78567814\n",
      " -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862 -0.83451376\n",
      " -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102 -0.88638487\n",
      " -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535 -0.94148015\n",
      " -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99       -1.\n",
      " -0.62352539 -0.62982363 -0.63618549 -0.6426116  -0.64910263 -0.65565922\n",
      " -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909 -0.69641322\n",
      " -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337 -0.73970037\n",
      " -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136 -0.78567814\n",
      " -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862 -0.83451376\n",
      " -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102 -0.88638487\n",
      " -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535 -0.94148015\n",
      " -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99       -1.\n",
      " -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.61729014 -0.62352539 -0.62982363 -0.63618549 -0.6426116\n",
      " -0.64910263 -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546\n",
      " -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034\n",
      " -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315\n",
      " -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694\n",
      " -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581\n",
      " -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469\n",
      " -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801\n",
      " -0.99       -1.         -0.62982363 -0.63618549 -0.6426116  -0.64910263\n",
      " -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546\n",
      " -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034\n",
      " -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315\n",
      " -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694\n",
      " -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581\n",
      " -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469\n",
      " -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801\n",
      " -0.99       -1.         -0.62982363 -0.63618549 -0.6426116  -0.64910263\n",
      " -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.62352539 -0.62982363 -0.63618549 -0.6426116  -0.64910263\n",
      " -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.6426116  -0.64910263 -0.65565922 -0.66228204 -0.66897176\n",
      " -0.67572905 -0.6825546  -0.68944909 -0.69641322 -0.70344769 -0.71055323\n",
      " -0.71773053 -0.72498034 -0.73230337 -0.73970037 -0.74717209 -0.75471929\n",
      " -0.76234271 -0.77004315 -0.77782136 -0.78567814 -0.79361428 -0.80163059\n",
      " -0.80972787 -0.81790694 -0.82616862 -0.83451376 -0.84294319 -0.85145777\n",
      " -0.86005835 -0.86874581 -0.87752102 -0.88638487 -0.89533825 -0.90438208\n",
      " -0.91351725 -0.92274469 -0.93206535 -0.94148015 -0.95099005 -0.96059601\n",
      " -0.970299   -0.9801     -0.99       -1.         -0.63618549 -0.6426116\n",
      " -0.64910263 -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546\n",
      " -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034\n",
      " -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315\n",
      " -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694\n",
      " -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581\n",
      " -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469\n",
      " -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801\n",
      " -0.99       -1.         -0.62352539 -0.62982363 -0.63618549 -0.6426116\n",
      " -0.64910263 -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546\n",
      " -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034\n",
      " -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315\n",
      " -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694\n",
      " -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581\n",
      " -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469\n",
      " -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801\n",
      " -0.99       -1.         -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.6426116  -0.64910263 -0.65565922 -0.66228204 -0.66897176\n",
      " -0.67572905 -0.6825546  -0.68944909 -0.69641322 -0.70344769 -0.71055323\n",
      " -0.71773053 -0.72498034 -0.73230337 -0.73970037 -0.74717209 -0.75471929\n",
      " -0.76234271 -0.77004315 -0.77782136 -0.78567814 -0.79361428 -0.80163059\n",
      " -0.80972787 -0.81790694 -0.82616862 -0.83451376 -0.84294319 -0.85145777\n",
      " -0.86005835 -0.86874581 -0.87752102 -0.88638487 -0.89533825 -0.90438208\n",
      " -0.91351725 -0.92274469 -0.93206535 -0.94148015 -0.95099005 -0.96059601\n",
      " -0.970299   -0.9801     -0.99       -1.         -0.6426116  -0.64910263\n",
      " -0.65565922 -0.66228204 -0.66897176 -0.67572905 -0.6825546  -0.68944909\n",
      " -0.69641322 -0.70344769 -0.71055323 -0.71773053 -0.72498034 -0.73230337\n",
      " -0.73970037 -0.74717209 -0.75471929 -0.76234271 -0.77004315 -0.77782136\n",
      " -0.78567814 -0.79361428 -0.80163059 -0.80972787 -0.81790694 -0.82616862\n",
      " -0.83451376 -0.84294319 -0.85145777 -0.86005835 -0.86874581 -0.87752102\n",
      " -0.88638487 -0.89533825 -0.90438208 -0.91351725 -0.92274469 -0.93206535\n",
      " -0.94148015 -0.95099005 -0.96059601 -0.970299   -0.9801     -0.99\n",
      " -1.         -0.63618549 -0.6426116  -0.64910263 -0.65565922 -0.66228204\n",
      " -0.66897176 -0.67572905 -0.6825546  -0.68944909 -0.69641322 -0.70344769\n",
      " -0.71055323 -0.71773053 -0.72498034 -0.73230337 -0.73970037 -0.74717209\n",
      " -0.75471929 -0.76234271 -0.77004315 -0.77782136 -0.78567814 -0.79361428\n",
      " -0.80163059 -0.80972787 -0.81790694 -0.82616862 -0.83451376 -0.84294319\n",
      " -0.85145777 -0.86005835 -0.86874581 -0.87752102 -0.88638487 -0.89533825\n",
      " -0.90438208 -0.91351725 -0.92274469 -0.93206535 -0.94148015 -0.95099005\n",
      " -0.96059601 -0.970299   -0.9801     -0.99       -1.         -0.63618549\n",
      " -0.6426116  -0.64910263 -0.65565922 -0.66228204 -0.66897176 -0.67572905\n",
      " -0.6825546  -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053\n",
      " -0.72498034 -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271\n",
      " -0.77004315 -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787\n",
      " -0.81790694 -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835\n",
      " -0.86874581 -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725\n",
      " -0.92274469 -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299\n",
      " -0.9801     -0.99       -1.         -0.62352539 -0.62982363 -0.63618549\n",
      " -0.6426116  -0.64910263 -0.65565922 -0.66228204 -0.66897176 -0.67572905\n",
      " -0.6825546  -0.68944909 -0.69641322 -0.70344769 -0.71055323 -0.71773053\n",
      " -0.72498034 -0.73230337 -0.73970037 -0.74717209 -0.75471929 -0.76234271\n",
      " -0.77004315 -0.77782136 -0.78567814 -0.79361428 -0.80163059 -0.80972787\n",
      " -0.81790694 -0.82616862 -0.83451376 -0.84294319 -0.85145777 -0.86005835\n",
      " -0.86874581 -0.87752102 -0.88638487 -0.89533825 -0.90438208 -0.91351725\n",
      " -0.92274469 -0.93206535 -0.94148015 -0.95099005 -0.96059601 -0.970299\n",
      " -0.9801     -0.99       -1.          0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "47.904761904761905\n",
      "Episode Number:  8 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.44752321 -0.45204365 -0.45660975 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "47.857142857142854\n",
      "Episode Number:  9 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.43423133 -0.4386175  -0.44304798 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "48.904761904761905\n",
      "Episode Number:  10 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42559012 -0.42988901 -0.43423133 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "49.0\n",
      "Episode Number:  11 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42559012 -0.42988901 -0.43423133 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "48.80952380952381\n",
      "Episode Number:  12 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42133422 -0.42559012 -0.42988901 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n",
      "49.23809523809524\n",
      "Episode Number:  13 | Total Reward:  -21.0\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[-0.42133422 -0.42559012 -0.42988901 ... -0.99       -1.\n",
      "  0.        ]\n",
      "\n",
      "Epoch 1: saving model to dumb_model.h5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bh/bkzmld751m5fdgn8m3_kzfmc0000gn/T/ipykernel_3574/1054613547.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2347\u001b[0m                     )\n\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2349\u001b[0;31m             data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   2350\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2283\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-private-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_FlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     variant_tensor = gen_dataset_ops.flat_map_dataset(\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mflat_map_dataset\u001b[0;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[1;32m   2354\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2357\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FlatMapDataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "observation = env.reset() # initialize to first frame\n",
    "prev_input = None\n",
    "\n",
    "total_frames = 0\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    cur_input = prepro(observation) # frame preprocessed\n",
    "    \n",
    "    \n",
    "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80) \n",
    "    \n",
    "    prev_input = cur_input\n",
    "    \n",
    "    x = np.expand_dims(x, axis=1).T\n",
    "    \n",
    "    prob = model.predict(x, verbose=False)\n",
    "    \n",
    "    \n",
    "    action = UP_ACTION if np.random.uniform() < prob else DOWN_ACTION # The neural net returns a probability\n",
    "    \n",
    "    y = 1 if action == 2 else 0 # converting between output of neural net and up/down action\n",
    "    \n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "    \n",
    "    \n",
    "    observation, reward, done, info = env.step(action) \n",
    "    \n",
    "    rewards.append(reward)\n",
    "    total_frames += 1\n",
    "    \n",
    "    if done: # episode finished after 21 games are won by either player\n",
    "        print(total_frames / 21)\n",
    "        total_frames = 0\n",
    "        reward_sum = np.sum(rewards)\n",
    "        history.append(reward_sum)\n",
    "        print(\"Episode Number: \", episode_num, \"| Total Reward: \", reward_sum)\n",
    "        \n",
    "        # x: image arrays, y=action performed, weights:\n",
    "        \n",
    "        disc = discount_rewards(rewards, gamma)\n",
    "        print(disc)\n",
    "            \n",
    "        model.fit(x=np.vstack(x_train), \n",
    "                  y=np.vstack(y_train), \n",
    "                  sample_weight=disc,\n",
    "                  verbose=0, callbacks=callbacks_list)\n",
    "        \n",
    "        \n",
    "        x_train, y_train, rewards = [],[],[]\n",
    "        observation = env.reset()\n",
    "\n",
    "        episode_num += 1\n",
    "        prev_input = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "288685f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7fbb208a87c0>\n"
     ]
    }
   ],
   "source": [
    "# loading the model\n",
    "dumb_model = load_model(filepath)\n",
    "print(dumb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc77c449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
