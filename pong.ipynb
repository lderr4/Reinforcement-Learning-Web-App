{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d27e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "# gym initialization\n",
    "env = gym.make('Pong-v0')\n",
    "observation = env.reset()\n",
    "prev_input = None\n",
    "# Declaring the two actions that can happen in Pong for an agent, move up or move down\n",
    "# Decalring 0 means staying still. Note that this is pre-defined specific to package.\n",
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "# Hyperparameters. Gamma here allows you to measure the effect of future events\n",
    "gamma = 0.99\n",
    "# initialization of variables used in the main loop\n",
    "x_train, y_train, rewards = [], [], []\n",
    "reward_sum = 0\n",
    "episode_num = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b43a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6000 (75x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop - remove 35px from start & 25px from end of image in x, to reduce redundant parts of image (i.e. after ball passes paddle)\n",
    "    I = I[::2,::2,0] # downsample by factor of 2.\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1. this makes the image grayscale effectively\n",
    "    return I.astype(np.float).ravel() # ravel flattens an array and collapses it into a column vector\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e595aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(22):\n",
    "    if i > 20:\n",
    "        plt.imshow(observation)\n",
    "        plt.show() # before preprocessing\n",
    "    observation, _, _, _ = env.step(1)\n",
    "    \n",
    "obs_preprocessed = prepro(observation).reshape(80,80)\n",
    "print(np.unique(obs_preprocessed,return_counts=True)) # binary array\n",
    "plt.imshow(obs_preprocessed, cmap='gray')\n",
    "plt.show() # after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(r, gamma): # idea: \n",
    "    r = np.array(r)\n",
    "    discounted_r = np.zeros(r.shape)\n",
    "    running_add = 0\n",
    "    print(discounted_r)\n",
    "\n",
    "    for t in reversed(range(0, len(r))): \n",
    "        \n",
    "        if r[t] != 0: running_add = 0 # if the game ended reset \n",
    "        running_add = running_add * gamma + r[t] \n",
    "        discounted_r[t] = running_add\n",
    "        \n",
    "    # not sure whether normalizing is helpful or not:\n",
    "    \n",
    "    # discounted_r -= np.mean(discounted_r) \n",
    "    # discounted_r /= np.std(discounted_r)\n",
    "    \n",
    "    \n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58edfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# models\n",
    "from keras.models import Sequential\n",
    "\n",
    "# optimizer \n",
    "from keras.optimizers import Adam # adaptive moment estimation, a type of stochastic gradient descent\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=200,\n",
    "                input_dim=80*80,\n",
    "                activation='relu',\n",
    "                kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid',\n",
    "                kernel_initializer='RandomNormal'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873bea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3,4,5],[4,5,6,5,4], [7,7,7,7,7]]\n",
    "print(np.vstack(a).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "observation = env.reset() # initialize to first frame\n",
    "prev_input = None\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    cur_input = prepro(observation) # frame preprocessed\n",
    "    \n",
    "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80) \n",
    "    \n",
    "    prev_input = cur_input\n",
    "    \n",
    "    \n",
    "    x = np.expand_dims(x, axis=1).T\n",
    "    prob = model.predict(x, verbose=False)\n",
    "    \n",
    "    \n",
    "    action = UP_ACTION if np.random.uniform() < prob else DOWN_ACTION # The neural net returns a probability\n",
    "    \n",
    "    y = 1 if action == 2 else 0 # converting between output of neural net and up/down action\n",
    "    \n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "    \n",
    "    \n",
    "    observation, reward, done, info = env.step(action) \n",
    "    \n",
    "    rewards.append(reward)\n",
    "    \n",
    "    \n",
    "    if done: # episode finished after 21 games are won by either player\n",
    "        reward_sum = np.sum(rewards)\n",
    "        history.append(reward_sum)\n",
    "        print(\"Episode Number: \", episode_num, \"| Total Reward: \", reward_sum)\n",
    "        \n",
    "        # x: image arrays, y=action performed, weights:\n",
    "        \n",
    "        disc = discount_rewards(rewards, gamma)\n",
    "        print(disc)\n",
    "            \n",
    "        model.fit(x=np.vstack(x_train), \n",
    "                  y=np.vstack(y_train), \n",
    "                  sample_weight=disc,\n",
    "                  verbose=0)\n",
    "        \n",
    "        \n",
    "        x_train, y_train, rewards = [],[],[]\n",
    "        observation = env.reset()\n",
    "\n",
    "        episode_num += 1\n",
    "        prev_input = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288685f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
